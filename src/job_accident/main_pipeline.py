import sys
import os 
current_dir = os.path.dirname(os.path.abspath(__file__))
# å‡è¨­ä½ çš„çµæ§‹æ˜¯ src/job_accident/main_pipeline.pyï¼Œæˆ‘å€‘è¦å¾€ä¸Šçˆ¬å…©å±¤åˆ° src
src_path = os.path.abspath(os.path.join(current_dir, "../../"))
if src_path not in sys.path:
    sys.path.append(src_path)

    
from e_crawler_accident import (auto_scrape_and_download_old_data,
                     auto_scrape_recent_data,
                     read_old_data_to_dataframe)
from t_dataclr_accident import (car_crash_old_data_clean,
                     transform_data_dict)
from l_tomysql_accident import (load_to_mysql,
                           load_to_new_mysql)
from l_tomysqlgcp_accident import (
                           load_to_GCP_mysql,
                           load_to_new_GCP_mysql,
                           load_cmp_to_new_GCP_mysql)
from l_setpkfk_accident import (
                           setting_pkfk,
                           setting_new_pkfk)

import pandas as pd
from sqlalchemy import inspect,text,create_engine
from create_table.create_accident_table import (SAVE_OLD_DATA_DIR,
                    SEQ_PAGE_URL,
                    SAVE_NEW_DATA_DIR,
                    GCP_DB_URL)
pd.set_option('future.no_silent_downcasting', True)#é—œé–‰è­¦å‘Š

def is_db_ready(engine):
    """æª¢æŸ¥ä¸»è¡¨æ˜¯å¦å­˜åœ¨ä¸”å·²æœ‰è³‡æ–™"""
    try:
        inspector = inspect(engine)
        if 'accident_sq1_main' in inspector.get_table_names():
            with engine.connect() as conn:
                count = conn.execute(text("SELECT COUNT(*) FROM accident_new_sq1_main")).scalar()
                return count > 0
    except Exception:
        return False
    return False

def run_accident_full_pipeline():
    """å°‡åŸæœ¬ if __name__ == "__main__" çš„é‚è¼¯åŒ…é€²ä¾†"""
    print("Airflow ä»»å‹™é–‹å§‹åŸ·è¡Œ...")
    engine = create_engine(GCP_DB_URL)

    # 1. æª¢æŸ¥è³‡æ–™åº«ç‹€æ…‹ (åŸæœ¬çš„ is_db_ready é‚è¼¯)
    if not is_db_ready(engine):
        print("ğŸ“ åµæ¸¬åˆ°è³‡æ–™åº«å°šæœªåˆå§‹åŒ–ï¼Œæº–å‚™åŒ¯å…¥æ­·å¹´è³‡æ–™...") 
        # ... (ä¸­é–“é‚£ä¸€å¤§æ®µæ­·å¹´è³‡æ–™è™•ç†é‚è¼¯) ...
        # æ³¨æ„ï¼šåœ¨ Docker ä¸­ SAVE_OLD_DATA_DIR å¿…é ˆæ˜¯ç›¸å°è·¯å¾‘æˆ–å®¹å™¨å…§è·¯å¾‘
        os.makedirs(SAVE_OLD_DATA_DIR, exist_ok=True)
        os.makedirs(SAVE_NEW_DATA_DIR, exist_ok=True)
        files = os.listdir(SAVE_OLD_DATA_DIR)
        #os.listdiré€™å€‹methodæœƒå»è·¯å¾‘ä¸‹çœ‹æª”æ¡ˆ
        if len(files)>0:
            for item in files:
                full_path = os.path.join(SAVE_OLD_DATA_DIR,item)
                old_list=read_old_data_to_dataframe(full_path)
                trans=transform_data_dict(old_list)
                cleaned=car_crash_old_data_clean(trans)
                clean1 = cleaned['main']
                clean2 = cleaned['party']
                db_engine = load_to_GCP_mysql(clean1,clean2)
                #db_engine=load_to_mysql(clean1,clean2)
            if db_engine:
                setting_pkfk(db_engine)
        else:
            for i in range(len(SEQ_PAGE_URL)):
                old=auto_scrape_and_download_old_data(SEQ_PAGE_URL[i])
                trans=transform_data_dict(old)
                cleaned=car_crash_old_data_clean(trans)
                clean1 = cleaned['main']
                clean2 = cleaned['party']
                db_engine=load_to_GCP_mysql(clean1,clean2)
                #db_engine= load_to_mysql(clean1,clean2)
            if db_engine:
                setting_pkfk(db_engine)

    # 2. æŠ“å–è¿‘æœŸè³‡æ–™ä¸¦ä¸Šå‚³
    print("ğŸš€ é–‹å§‹æŠ“å–è¿‘æœŸè³‡æ–™...")
    new = auto_scrape_recent_data()
    trans = transform_data_dict(new)
    cleaned = car_crash_old_data_clean(trans)
    clean1 = cleaned['main']
    clean2 = cleaned['party']
    db_engine = load_cmp_to_new_GCP_mysql(clean1, clean2)
    
    if db_engine:
        setting_new_pkfk(db_engine)
    
    print("âœ… ETL ä»»å‹™é †åˆ©å®Œæˆ")
    return True




if __name__ == "__main__":
    run_accident_full_pipeline()
